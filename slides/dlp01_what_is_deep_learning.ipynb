{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1장 딥러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1 인공지능과 머신러닝, 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 관계 1: 연구 분야\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ai-ml-relation.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [교보문고: 에이지 오브 머신러닝](http://www.kyobobook.co.kr/readIT/readITColumnView.laf?thmId=00198&sntnId=14142)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 관계 2: 역사\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ai-ml-relation2.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "그림 출처: [NVIDIA 블로그](https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 인공지능\n",
    "\n",
    "- 1950년대: 컴퓨터가 생각할 수 있는가? 라는 질문에서 출발\n",
    "- 1956년: 존 맥카시(John McCarthy)의 제안에 의해 연구분야로 자리잡음.\n",
    "    - 목표: 인간의 모든 지능 활동을 컴퓨터로 구현하기\n",
    "- 정의: 사람의 지능적 작업을 컴퓨터로 자동화하는 노력\n",
    "- 머신러닝과 딥러닝이 포함됨\n",
    "- 1980년대까지는 __학습__(러닝)이 아닌 모든 것을 정해진 규칙대로 움직이는\n",
    "    __심볼릭 AI__(symbolic AI)가 주로 연구되었음.\n",
    "    - 모든 가능성을 논리적으로 전개하는 기법\n",
    "    - 서양장기(체스) 등에서 우수한 성능 발휘\n",
    "    - 반면에 이미지 분류, 음석 인식, 자연어 번역 등 보다 복잡한 문제는 제대로 다루지 못함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 머신러닝\n",
    "\n",
    "- 머신러닝 시스템: \n",
    "    - 명시적인 규칙(명령문)만을 수행하지 않음.\n",
    "    - 대신 데이터로부터 특정 통계적 구조를 학습하여 지정된 작업을 \n",
    "        스스로(자동으로) 완수할 수 있는 규칙을 생성함.\n",
    "    - 사진 태그 시스템 예제: 태그 달린 사진을 이용하여 학습하면 사진에 자동으로 태그를 다는 데에 사용되는 \n",
    "- 1990년대에 보다 빨라진 하드웨어와 보다 커진 데이터셋의 영향으로 본격적으로 발전 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-a-new-programming-paradigm.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-a-new-programming-paradigm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 머신러닝 대 통계학\n",
    "\n",
    "- 머신러닝의 기초는 통계학. 1학기 내용 참조.\n",
    "- 하지만 아주 큰 데이터(빅데이터)를 단순히 통계학적으로 다룰 수는 없음.\n",
    "- 특히 딥러닝의 경우 수학적, 통계적 이론 보다는 공학적 접근법이 보다 중요해짐.\n",
    "- 소프트웨어와 하드웨어의 발전에 보다 의존함을 이어지는 내용을 다루면서 계속해서 확인하게 될 것임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 데이터 표현법 학습\n",
    "\n",
    "- 데이터 __표현__(representation): 데이터를 컴퓨터가 다룰 수 있는 자료형으로 구현하기\n",
    "- 예제: 컬러 이미지 표현법\n",
    "    - 빨간색-초록색-파란색을 사용하는 RGB 방식 또는 색상-채도-명도를 사용하는 HSV 방식\n",
    "- 주어진 과제에 따라 적절한 표현법 선택해야 함\n",
    "    - 컬러 사진에서 빨간색 픽셀만을 선택하고자 할 때: RGB 방식 활용\n",
    "    - 컬리 이미지의 채도를 낮추고자 할 때: HSV 방식 활용   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 머신러닝 모델\n",
    "\n",
    "- 필요 사항\n",
    "    - 입력 데이터셋: 음성 인식 모델을 위한 음성 파일, 이미지 태깅 모델을 위한 사진 등.\n",
    "    - 기대 출력값: 음성 인식 작업의 경우 사람이 직접 작성한 글, 이미지 작업의 경우 '강아지', \n",
    "        '고양이', 등의 사람이 직접 붙힌 태그.\n",
    "    - 알고리즘 성능측정법: 출력 예상값과 기대 출력값 사이의 거리(차이) 측정법. \n",
    "        거리를 줄이는 방향으로 알고리즘에 사용되는 파라미터를 반복 수정하는\n",
    "        과정을 __학습__이라 부름.\n",
    "- 역할: 입력 데이터를 적절한 표현으로 변환한 후, 변환된 테이터셋으로부터 \n",
    "    과제 해결을 위한 적절한 수학적, 통계적 규칙 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 예제: 선형 분류\n",
    "\n",
    "1. 왼쪽 그림: 입력 데이터셋\n",
    "1. 가운데 그림: 부적절한 좌표 변환. 분류 과제 해결에 적합하지 않음.\n",
    "1. 오른쪽 그림: 적절한 좌표 변환. 분류 과제를 보다 효율적으로 해결할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-learning_representations.png\" style=\"width:700px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-learning_representations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 데이터 변환 수동화의 어려움\n",
    "\n",
    "- 위 예제의 경우 수동으로 데이터 변환 방식을 어렵지 않게 알아낼 수 있음.\n",
    "- 반면에 손글씨 숫자 인식(MNIST)의 경우 간단하지 않음(아래 그림 참조). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch03/homl03-10.png\" width=\"300\"/></div>\n",
    "\n",
    "그림 출처: [핸즈온 머신러닝(2판)](https://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 데이터 변환 자동화\n",
    "\n",
    "- 보다 유용한 데이터 표현으로 변환하는 과정을 자동으로 찾는 과정이 머신러닝 모델의 학습을 의미함.\n",
    "- __데이터 표현의 유용성__에 대한 기준: 주어진 과제 해결을 위한 보다 쉬운 규칙 제공\n",
    "- 변환 방식 종류\n",
    "    - 좌표 변환, 픽셀 개수, 닫힌 원의 개수, 선형/비선형 변환, 이동, ...\n",
    "    - 기본적으로 주어진 문제에 따라 다른 변환 방식 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "#### 가설 공간\n",
    "\n",
    "- 주어진 문제에 대해 어느 변환이 좋은지 머신러닝 알고리즘은 일반적으로 쉽게 알아내지 못함.\n",
    "- 프로그래머에 의해 지정된 함수들의 집합(__가설 공간__)에서 적합한 변환 함수를 탐색하는 일만 수행함.\n",
    "- 예제: 위 2차원 좌표 변환 문제의 가설 공간은 '모든 가능한 좌표 변환 함수'들의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝의 '딥'(deep)이란?\n",
    "\n",
    "- 딥러닝: 머신러닝의 연구 분야 중 하나\n",
    "- '딥'(deep)의 의미: __데이터 표현의 연속적 변환__을 지원하는 여러 개의 '층'(layer)을 활용한 학습\n",
    "- 즉 __계층적 표현 학습__을 지원하는 머신러닝을 딥러닝이라 부름.\n",
    "- 딥러닝 모델의 깊이 = 계층으로 쌓아 올린 층의 높이\n",
    "    - 수 십개 또는 수 백개의 층으로 구성된 모델 존재\n",
    "    - 모든 층에서 데이터 표현의 변환이 __자동__으로 이루어지는 것이 핵심!\n",
    "- 섈로러닝(shallow learning): 한 두 개의 층만 사용하는 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch14/homl14-15b.png\" width=\"700\"/></div>\n",
    "\n",
    "<그림 참조: [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 신경망\n",
    "\n",
    "- 신경망(neural network): 계층적 표현 학습이 이루어지는 모델\n",
    "    - __계층적 '인풋-투-타깃'(input-to-target) 변환__ 학습 모델\n",
    "    - 예제: 숫자 이미지 $\\Rightarrow \\cdots \\Rightarrow$ 숫자\n",
    "- __주의사항__: 뇌 과학과 아무 상관 없음!\n",
    "- 단순하지만 매우 강력한 결과를 생산하는 아이디어!\n",
    "- 예제: 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-mnist_representations.png\" style=\"width:600px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-mnist_representations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝 작동 원리\n",
    "\n",
    "딥러닝 모델의 작동 원리를 이해하려면 다음 세 개념에 집중해야 함\n",
    "- 가중치(weight)\n",
    "- 손실 함수(loss function)\n",
    "- 역전파(backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### A. 가중치\n",
    "\n",
    "- 데이터 표현의 변환에 사용되는 __파라미터__(parameter)\n",
    "- 학습: 적절한 가중치를 모든 층에 대해 동시에(!) 찾는 과정\n",
    "    - 하나의 가중치가 변하면 모든 다른 가중치도 변함!\n",
    "- 많게는 수 천만 개의 가중치를 학습해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-1.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 예제: 다층 퍼셉트론(MLP, multilayer perceptron)\n",
    "\n",
    "- 가장 간단한 형태의 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch10/homl10-08.png\" width=\"400\"/></div>\n",
    "\n",
    "그림 출처: [핸즈온 머신러닝(2판)](https://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 유닛(unit) 작동 원리\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch10/homl10-01.png\" width=\"300\"/></div>\n",
    "\n",
    "그림 출처: [핸즈온 머신러닝(2판)](https://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### B. 손실 함수\n",
    "\n",
    "- 신경망의 출력값(output)과 타깃(target) 사이의 거리를 측정하는 함수\n",
    "    - 가중치에 의존하는 함수\n",
    "- __목적 함수__(objective function) 또는 __비용 함수__(cost function)라고도 불림\n",
    "- 손실 함수의 반환값을 학습 과정 중의 피드백으로 활용하여 \n",
    "    얼마나 잘 학습되고 있는지 확인하는 데에 사용함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-2.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### C. 역전파\n",
    "\n",
    "- 역전파(backpropagation) 알고리즘: 손실함수의 출력값과 타깃 사이의 거리를 좁히는 방향으로 가중치를 조절하는 알고리즘\n",
    "- 옵티마이저(optimizer): 역전파 알고리즘을 구현한 프로그램. 다양한 옵티마이저 중 적절한 것을 선택해야 함.\n",
    "- 가중치 업데이트 과정\n",
    "    - 모든 가중치 무작위 초기화: 결과적으로 손실값 매우 높음.\n",
    "    - 훈련 반복: 손실값이 낮아지도록 가중치 조절. \n",
    "        경사하강법에 기초한 역전파 활용(옵티마이저의 역할)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-3.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-deep-learning-in-3-figures-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 지금까지 딥러닝의 성과\n",
    "\n",
    "- 사람과 비슷한 수준의 이미지 분류, 음성 인식, 필기 인식, 자율 주행\n",
    "- 급격하게 향상된 기계 번역, TTS(text-to-speech) 변환\n",
    "- 구글 어시스턴트, 아마존 알레사 등의 디지털 도우미\n",
    "- 향상된 광고 타게팅, 웹 검색\n",
    "- 자연어 질문 대처 능력\n",
    "- 사람을 능가하는 바둑 실력(2013 알파고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 전망\n",
    "\n",
    "- 단기적으로 너무 높은 기대를 갖는 것은 위험함.\n",
    "    - 실망할 경우 AI에 대한 투자가 급속도로 줄어들 수 있음. \n",
    "    - 1970년대와 1990년대 1차, 2차 AI 겨울(AI winter)가 실제로 존재했었음.\n",
    "- 2020년대 초반 현재 중요한 문제에 본격적으로 딥러닝을 적용하기 시작하고 있음.\n",
    "- 하지만 대부분의 연구 결과과 제대로 실용적으로 활용되지 못하고 있음.\n",
    "- 인터넷이 가져올 영향에 대해 1995년 경에 제대로 몰랐듯이 앞으로 딥러닝의 가졍올 영향에 대해\n",
    "    제대로 알 수 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 딥러닝 이전: 머신러닝의 역사\n",
    "\n",
    "- 산업계에서 사용되는 머신러닝 알고리즘의 대부분은 딥러닝 알고리즘이 아님.\n",
    "- 훈련에 사용할 데이터가 너무 적거나, 아니면 딥러닝이 아닌 다른 알고리즘이 보다 좋은 해결책을 제시할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 확률적 모델링\n",
    "\n",
    "- 나이브 베이즈 알고리즘(Naive Bayes algorithm)을 활용하는 분석 기법이 대표적임.\n",
    "- 베이즈 정리(Bayes theorem)에 기초하는 전통적인 기법\n",
    "- 1950년대 부터 컴퓨터 없이 적용 시작\n",
    "- 베이즈 정리 등 확률록의 기초는 18세기부터 시작됨.\n",
    "- 예제: 로지스틱 회귀(logistic regression, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 초창기 신경망\n",
    "\n",
    "- 기본 아이디어: 1950년대부터 연구됨.\n",
    "- 성공적 구현: 1989년 벨 연구소(Bell Labs)의 얀 르쿤(Yann LeCun)의한 합성곱 신경망 LeNet\n",
    "    - 손글씨 숫자 이미지 자동 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch14/homl14-16.gif\" width=\"400\"/></div>\n",
    "\n",
    "< 그림 출처: [LeNet-T CNN](http://yann.lecun.com/exdb/lenet/index.html) > "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 커널 기법\n",
    "\n",
    "- 1990년대: 서포트 벡터 머신(SVM) + 커널 기법\n",
    "- 매우 성공적으로 활용됨.\n",
    "- 초창기 신경망 성능을 뛰어 넘음.\n",
    "- 한계\n",
    "    - 대용량 데이터셋 처리에 부적합(매우 느림)\n",
    "    - 이미지 분류 등 지각 문제 해결 잘 못함\n",
    "- __특성 공학__(feature engineering)에 약함: 유용한 데이터 표현으로의 변환을 수동을 해결해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 결정트리, 랜덤 포레스트, 그레이디언트 부스팅 머신\n",
    "\n",
    "- 결정트리: 입력값을 순서도 형식으로 특정 기준으로 분류하는 방식\n",
    "    - 2000년대에 본격적으로 연구됨\n",
    "- 랜덤 포레스트: 2010년 경 커널기법보다 선호됨.\n",
    "- 그레이디언트 부스팅 머신:2014년 경 가장 선호되는 앙상블 학습 기법\n",
    "    - 지각 문제 이외의 경우 여전히 가장 성능이 좋은 모델 중 하나임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-decision_tree.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ch01-decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝의 본격적 발전\n",
    "\n",
    "- 2011년: GPU를 활용한 딥 신경망 훈련 시작\n",
    "- 2012년: ImageNet Challenge에서 그 이전에 비해 획기적으로 향상된 모델 제공\n",
    "    - 2011년 최고 성능: 74.3%의 정확도\n",
    "    - 2012년 합성곱 신경망(convnet)의 최고 성능: 83.6%의 정확도\n",
    "    - 2015년 최고 성능: 96.4%의 정확도\n",
    "    - ImageNet Challenge 대회 더 이상 진행되지 않음.\n",
    "- 2015년 이후: 많은 문제 영역에서 SVM, 결정트리 등을 딥러닝 모델로 대체함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝의 특징\n",
    "\n",
    "- 자동화된 데이터 표현의 변환, 즉 특성 공학 자동화\n",
    "- 층을 거치면서 점진적으로 더 복잡한 데이터 표현을 만들어 냄.\n",
    "- 이 모든 과정에서의 데이터 표현의 변환, 즉 모든 층에 대한 특성 공학을 스스로 학습함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 최근 머신러닝 분야의 동향\n",
    "\n",
    "- 2019년 캐글(Kaggle) 경진대회에서 상위팀이 사용한 도구 설문조사 결과\n",
    "- 딥러닝 기법 또는 그레이디언트 부스팅 기법이 주로 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_top_teams_tools.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_top_teams_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터과학 일반에서 가장 많이 사용되는 도구(캐글 설문조사 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_ds_survey_2020.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/kaggle_ds_survey_2020.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
