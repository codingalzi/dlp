{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5장 머신러닝의 핵심 이슈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝의 핵심 이슈 이해: 모델 일반화와 모델 훈련 최적화 사이의 관계 조율\n",
    "- 머신러닝 모델 평가 기법\n",
    "- 모델 훈련 최적화 기법\n",
    "- 모델 일반화 성능 향상 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.1 머신러닝의 목표: 모델 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과대적합 현상 언제나 발생: 훈련을 많이 할 수록 모델은 훈련 세트에 비해 새로운 데이터에 대한 \n",
    "    성능이 점점 떨어짐.\n",
    "- 머신러닝의 핵심 이슈: 모델 훈련의 **최적화**(optimization)와 모델 **일반화**(generalization) 사이의 \n",
    "    적절한 조정\n",
    "    - **최적화**: 훈련 세트에 대해 가장 좋은 성능을 이끌어 내는 과정\n",
    "    - **일반화**: 처음 보는 데이터를 처리하는 모델의 능력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과소적합과 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과소적합\n",
    "    - 훈련 초반, 즉 훈련셋과 검증셋 모두에 대해 성능이 향상되는 과정\n",
    "    - 신경망이 훈련셋의 패턴을 아직 덜 파악한 상태\n",
    "\n",
    "- 과대적합\n",
    "    - 훈련셋 고유의 패턴을 학습하기 시작\n",
    "    - 새로운 데이터와 무관하거나 혼동을 주는 패턴 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 일반화 성능이 좋은 모델 대 과대적합 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 과대적합 발생 주요 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과대적합을 발생시키는 요소는 크게 세 가지로 나뉜다.\n",
    "\n",
    "##### 첫째, 소음(noise) 섞인 훈련셋.\n",
    "\n",
    "- 적절하지 않은 데이터 또는 잘못된 레이블을 갖는 데이터 등을 **소음** 또는 **노이즈**(noise)라 부름.\n",
    "- 적절하지 않은 데이터: 다음 MNNIST 이미지들처럼 불분명하면 특성 파악 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 잘못된 레이블: 예를 들어, 잘못 분류된 1처럼 생긴 이미지를 7로 잘못 분류할 가능성이 높아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 둘째, 애매한 특성.\n",
    "\n",
    "- 소음이 전혀 없는 데이터라 하더라도 특정 특성 영역이 여러 레이블과 연관될 수 있음.\n",
    "\n",
    "- 예제: 붓꽃 데이터의 꽃잎 길이와 너비를 활용한 \n",
    "    버시컬러(versicolor) 품종과 버지니카(virginica) 품종의 완벽한 구분 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png\" style=\"width:400px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 셋째: 매우 드문 특성 또는 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 매우 드문 특성\n",
    "    - 예제: IMDB 데이터셋에서 매우 낮은 빈도로 사용되는 단어를 훈련셋에서 포함시키는 경우\n",
    "        어쩌다 한 번 사용되는 특성으로 인해 잘못된 판단이 유도될 수 있음.\n",
    "\n",
    "- 거짓된 상관관계를 유발하는 훈련셋\n",
    "- 예제: MNIST 데이터셋에 **백색 소음**(white noise)이 포함된 데이터셋과 그렇지 않은 데이터셋 비교 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 딥러닝 모델 일반화의 핵심"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝 모델은 어떤 무엇도 학습할 수 있다.\n",
    "- 일반화는 모델 훈련 과정 중에 제어할 수 있는 대상이 아니다. \n",
    "- 모델 훈련을 통해 할 수 있는 것은 주어진 훈련 데이터셋에 모델이 적응하도록 하는 것 뿐이다.\n",
    "- 딥러닝 모델은 어떤 데이터셋에도 적응할 수 있기에 \n",
    "    너무 오래 훈련시키면 과대적합은 반드시 발생하고 일반화는 어려워진다. \n",
    "- 결론적으로 **일반화**가 모델 보다는 사용되는 **데이터셋 내부에 존재하는 정보 구조**와 \n",
    "    보다 밀접히 관련된다고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 다양체 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- **다양체 가설**(manifold hypothesis): 일반적인 데이터셋은 고차원상에 존재하는 \n",
    "    (저차원의) 연속이며 미분가능한 다양체를 구성한다\n",
    "- 모델 훈련: 바로 이 다양체를 찾아가는 과정\n",
    "- **참고**: 이런 의미에서 무작위로 섞은 레이블을 사용하는 위 MNIST 예제는 일반적인 데이터셋이 될 수 없음.\n",
    "- 예제: 3차원 공간에 존재하는 2차원 다양체를 고차원 상의 다양체로 변환하여 \n",
    "    선형 분류가 가능한 데이터셋을 구성하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch08/homl08-13.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "그림 출처: [핸즈온 머신러닝(2판), 8장](https://github.com/ageron/handson-ml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "다양체 가설을 이용하면 적절하게 구성된 모델이 적절한 훈련셋으로 훈련받았을 때 새로운 데이터에 대해 적절한 예측을 할 수 있는 이유를 설명할 수 있다.\n",
    "즉, 모델이 찾은 연속이며 미분가능한 다양체와 학습된 데이터 정보에 **보간법**을 적용하여 새로운 데이터에 대해 예측을 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보간법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**보간법**(interpolation)은 모델 훈련에 사용된 훈련셋의 데이터와 새로운 데이터를 연결하는 \n",
    "다양체 상의 경로를 이용하여 예측값을 실행하는 것을 의미한다. \n",
    "보다 큰 훈련셋을 사용할 수록 보간법이 보다 잘 작동하지만 \n",
    "**차원의 저주**(curse of dimensions)로 인해 충분한 크기의 훈련셋 구하기가 \n",
    "일반적으로 불가능하거나 매우 어렵다. \n",
    "    \n",
    "**참고**: 사람은 보간법 이외의 다른 능력을 사용하여 사물 예측과 구분, 주변 파악, 상황 판단 등 \n",
    "일반화를 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_sampling.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 충분치 않은 훈련셋과 정규화\n",
    "\n",
    "충분히 큰 훈련셋을 준비하지 못하면 예측 과정에서 과대한 추측을 하게되어 과대적합이 발생할 가능성이 높다.\n",
    "이를 방지하기 위해 일반적으로 두 가지 방법을 사용한다.\n",
    "\n",
    "- 모델에 저장되는 정보를 적절하게 조정하기\n",
    "- 모델이 생성하는 다양체의 곡률 완화\n",
    "\n",
    "위 두 방법을 통해 데이터셋의 너무 세세한 패턴 보다는 가장 눈에 띄는 핵심적인 패턴에 모델이 집중하도록 한다.\n",
    "이런식으로 과대적합을 방지하여 일반화를 향상시키는 기법을 **정규화**(regularization)이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.2 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 일반화 능력을 향상시키려면 주어진 모델의 일반화 능력을 평가할 수 있어야 하며,\n",
    "이를 위해 데이터셋을 훈련셋, 검증셋, 테스트셋으로 구분하는 이유를 먼저 알아야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 튜닝과 정보 유출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋, 테스트셋 이외에 검증셋을 사용해야 하는 이유는 \n",
    "무엇보다도 **최적의 모델을 구성할 때 검증셋에 대한 결과가 반영되기 때문**이다. \n",
    "\n",
    "테스트셋은 모델 구성과 훈련에 전혀 관여하지 않아야 한다.\n",
    "따라서 구성된 모델의 성능을 평가하려면 테스트셋을 제외한 다른 데이터셋이 필요하고\n",
    "이를 위해 훈련셋의 일부를 검증셋으로 활용한다.\n",
    "검증셋은 훈련 과정 중에 일반화 성능을 테스트하는 용도로 사용되며\n",
    "이를 통해 레이어 종류 및 개수, 레이어 별 유닛 개수 등 모델 구성에 필요한\n",
    "**하이퍼파라미터**(hyperparameter)를 조정한다. \n",
    "이것을 **모델 튜닝**(model tuning)이라 하며,\n",
    "바로 이 모델 튜닝을 위해 검증셋이 사용되는 것이다. \n",
    "\n",
    "모델 튜닝도 모델의 좋은 하이퍼파라미터를 찾아가는 일종의 **학습**이다. \n",
    "따라서 튜닝을 많이 하게되면 검증셋에 대한 과대적합이 발생한다.\n",
    "다시 말해, 검증셋에 특화된 튜닝을 하게 되어 모델의 일반화 성능이 떨어질 수 있게 된다. \n",
    "이런 현상을 **정보 유출**이라 부르는데,\n",
    "이유는 튜닝을 하면 할 수록 검증셋에 대한 보다 많은 정보가 모델로 흘려들어가기 때문이다. \n",
    "\n",
    "**참고**: 하이퍼파라미터와 파라미터는 다르다. \n",
    "파라미터(parameter)는 모델 훈련 중에 학습되는 가중치, 편향 등을 가리킨다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련셋, 검증셋, 테스트셋 분류 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋을 훈련셋, 검증셋, 테스트셋으로 분류하여 모델을 훈련을 진행하는\n",
    "전형적인 방식 세 가지를 소개한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 홀드아웃(hold-out) 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 일부를 검증셋으로 사용하는 가장 일반적인 방법이며,\n",
    "모델 훈련 후에 테스트셋을 이용하여 모델의 일반화 성능을 확인한다.\n",
    "하지만 테스트셋을 이용한 일반화 성능 확인 이후엔 모델 튜닝을 진행하지 않아야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/holdout_validation.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "홀드아웃 검증의 전형적인 패턴은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "training_data = data[num_validation_samples:]\n",
    "\n",
    "model = get_model()\n",
    "model.fit(training_data, ...)\n",
    "\n",
    "validation_score = model.evaluate(validation_data, ...)\n",
    "\n",
    "...\n",
    "\n",
    "model = get_model()\n",
    "model.fit(np.concatenate([training_data,\n",
    "                          validation_data]), ...)\n",
    "\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 성능이 사용되는 훈련셋에 따라 심하게 달라질 때 추천되는 검증기법이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/k_fold_validation.png\" style=\"width:650px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-겹 교차검증의 전형적인 패턴은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "```python\n",
    "k = 3\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "                           num_validation_samples * (fold + 1)]\n",
    "    training_data = np.concatenate(\n",
    "        data[:num_validation_samples * fold],\n",
    "        data[num_validation_samples * (fold + 1):])\n",
    "    \n",
    "    model = get_model()\n",
    "    model.fit(training_data, ...)\n",
    "    \n",
    "    validation_score = model.evaluate(validation_data, ...)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model = get_model()\n",
    "model.fit(data, ...)\n",
    "\n",
    "test_score = model.evaluate(test_data, ...)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 반복 K-겹 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련셋의 크기가 너무 작거나 모델의 성능을 최대한 정확하게 평가하기 위해 사용된다.\n",
    "K-겹 교차검증을 여러 번 실행한다. 대신 매번 훈련셋을 무작위로 섞은 뒤에\n",
    "교차검증을 실행한다. \n",
    "최종 결과는 각 교차검증의 평균값을 사용한다. \n",
    "훈련 시간이 매우 오래 걸린다는 게 이 방법의 단점이다. \n",
    "K-겹 교차 검증을 P번 반복하면 총 `P * K` 개의 모델을 훈련시키게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 성능 평가의 기준선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련이 시작되면 평가지표(metrics)를 지켜보는 일 이외에 할 수 있는 게 없다.\n",
    "따라서 검증셋에 대한 평가지표가 특정 기준선 이상인지를 아는 게 매우 중요하다.\n",
    "\n",
    "기준선 예제\n",
    "\n",
    "- MNIST 데이터셋: 10%의 정확도\n",
    "- IMDB 데이터셋: 50%의 정확도\n",
    "- 로이터 통신 기사: 18-19의 정확도. 이런 경우 정밀도 등 정확도 이외의 다른 평가기준도 고려 가능.\n",
    "\n",
    "기준선을 넘는 모델을 생성하는 것이 우선적인 목표이어야 한다.\n",
    "그렇지 않다면 무언가 잘못된 모델을 또는 잘못된 접근법을 사용하고 있을 가능성이 크다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 준비 관련 주의사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 최적화 훈련을 위해 아래 세 가지 사항을 준수하며 훈련셋, 검증셋, 테스트셋을 \n",
    "준비해야 한다. \n",
    "\n",
    "- **대표성**: 일반적으로 데이터셋을 무작위로 섞어 레이블이 적절한 비율로 섞인 \n",
    "    훈련셋, 검증셋, 테스트셋을 구성한다.\n",
    "- **시간의 흐름**: 미래를 예측하는 모델을 훈련시킬 때, 테스트셋의 데이터는 훈련셋의 데이터보다\n",
    "    시간상 뒤쪽에 위치하도록 한다. 그렇지 않으면 미래 정보가 모델에 유출된다.\n",
    "    즉, 데이터를 무작위로 섞어 훈련셋과 테스트셋으로 구분하는 일은 피하거나 조심스럽게 진행한다. \n",
    "- **중복 데이터 제거**: 훈련셋과 테스트셋에 동일한 데이터가 들어가지 않도록 중복 데이터를 제거한다."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
