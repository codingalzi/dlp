{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 7장 케라스 모델 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사말**: 프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 3장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다.\n",
    "\n",
    "**tensorflow 버전과 GPU 확인**\n",
    "- 구글 코랩 설정: '런타임 -> 런타임 유형 변경' 메뉴에서 GPU 지정 후 아래 명령어 실행 결과 확인\n",
    "\n",
    "    ```\n",
    "    !nvidia-smi\n",
    "    ```\n",
    "\n",
    "- 사용되는 tensorflow 버전 확인\n",
    "\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    tf.__version__\n",
    "    ```\n",
    "- tensorflow가 GPU를 사용하는지 여부 확인\n",
    "\n",
    "    ```python\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스 모델 구성법\n",
    "- 케라스 모델 훈련 및 평가\n",
    "- 사용자 정의 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.1 작업 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 이용하여 매우 단순한 모델부터 매우 복잡한 모델까지 구성 및 훈련이 가능하다. \n",
    "케라스의 모델과 층은 모두 각각 `Model` 클래스와 `Layer` 클래스를 상속하기에 \n",
    "다른 모델에서 사용된 요소들을 재활용하기에도 용이하다.\n",
    "\n",
    "여기서는 주어진 문제에 따른 케라스 모델 구성법과 훈련법의 다양한 방식을 살펴본다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.2 케라스 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 이용하여 모델을 세 가지 방식으로 구성할 수 있다.\n",
    "\n",
    "- `Sequential` 모델: 층으로 스택을 쌓아 만든 모델\n",
    "- 함수형 API 활용: 가장 많이 사용됨.\n",
    "- 모델 서브클래싱: 모든 것을 사용자가 지정.\n",
    "\n",
    "가장 간단한 모델부터 아주 복잡한 모델까지 모두 구성할 수 있으며\n",
    "사용자가 직접 정의한 모델과 레이어도 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 1: `Sequential` 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층으로 스택을 쌓아 만든 모델이며 가장 단순하다.\n",
    "\n",
    "- 하나의 입력값과 하나의 출력값만 사용 가능\n",
    "- 층을 지정된 순서대로만 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Sequential` 클래스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "층의 추가는 `add` 메서드를 이용할 수도 있다.\n",
    "더해진 순서대로 층이 쌓인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`build()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련에 사용되는 층별 가중치는 모델이 처음 활용될 때 호출되는\n",
    "`build()` 메서드에 의해 초기화된다.\n",
    "이유는 입력값이 들어와야 가중치 텐서의 모양(shape)을 정할 수 있기 때문이다. \n",
    "아래 코드 샘플은 [3장](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html)에서 \n",
    "`SimpleDense`를 선언할 때 사용된 `build()` 메서드를 보여주며,\n",
    "훈련이 시작되면서 첫 배치 데이터셋이 입력될 때 특성 수를 확인하여\n",
    "가중치와 편향 텐서를 생성과 동시에 초기화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build(self, input_shape):\n",
    "    input_dim = input_shape[-1]   # 입력 샘플의 특성 수\n",
    "    self.W = self.add_weight(shape=(input_dim, self.units),\n",
    "                             initializer=\"random_normal\")\n",
    "    self.b = self.add_weight(shape=(self.units,),\n",
    "                             initializer=\"zeros\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 지금 당장 가중치를 확인하려 하면 오류가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> model.weights\n",
    "...\n",
    "ValueError: Weights for model sequential_1 have not yet been created. \n",
    "Weights are created when the Model is first called on inputs or \n",
    "`build()` is called with an `input_shape`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "반면에 입력값 대신 `build()` 메서드를 특성 수 정보를 이용하여 직접 호출하면\n",
    "가중치 텐서가 무작위로 초기화된 형식으로 생성된다.\n",
    "즉, **모델 빌드**가 완성된다.\n",
    "\n",
    "- `input_shape` 키워드 인자: `(None, 특성수)`\n",
    "- `None`은 임의의 크기의 배치도 다룰 수 있다는 것을 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 빌드가 완성되면 `weights` 속성에 생성된 모델 훈련에 필요한 모든 가중치와 편향이 저장된다.\n",
    "위 모델에 대해서 층별로 가중치와 편향 텐서 하나씩 총 4 개의 텐서가 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`summary()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성된 모델의 요악한 내용은 확인할 수 있다.\n",
    "\n",
    "- 모델과 층의 이름\n",
    "- 층별 파라미터 수\n",
    "- 파라미터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`name` 인자**\n",
    "\n",
    "모델 또는 층을 지정할 때 생성자 메서등의 `name` 키워드 인자를 이용하여 이름을 지정할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Input()` 함수, `KerasTensor`, 모델 디버깅**\n",
    "\n",
    "모델 구성 중간에 구성 과정을 확인하려면 `Input()`함수를 이용하여\n",
    "**케라스텐서**(`KerasTensor`) 객체를\n",
    "가장 먼저 모델에 추가한다.\n",
    "그러면 층을 추가할 때마다 `summary()`를 실행할 수 있다.\n",
    "`Input()` 함수는 모델 훈련에 사용되는 데이터 샘플의 모양(shape) 정보를 제공하는 \n",
    "    가상의 텐서인 `KerasTensor` 객체를 생성한다.\n",
    "    \n",
    "**주의사항**: `shape` 키워드 인자에 사용되는 값은 각 샘플의 특성 수이며,\n",
    "앞서 `build()` 메서드의 인자와 다른 형식으로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 2: 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 입력과 다중 출력을 지원하려면 함수형 API를 활용하여 모델을 구성해야 하며,\n",
    "가장 많이 사용되는 모델 구성법이다. \n",
    "사용법은 간단하다.\n",
    "\n",
    "```python\n",
    "Model(inputs, outputs)\n",
    "```\n",
    "\n",
    "- `Model`: 케라사의 기본 모델 클래스\n",
    "- `inputs` 인자: 한 개 이상의 케라스텐서(`KerasTensor`) 객체 이루어진 리스트\n",
    "- `outputs` 인자: 한 개 이사의 출력층으로 이루어진 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살펴 본 `Sequential` 모델을 함수형 API를 이용하여 구성하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")          # 입력층\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)     # 은닉층\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features) # 출력층\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용된 단계들을 하나씩 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력층: `inputs = keras.Input(shape=(3,), name=\"my_input\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 값은 `KerasTensor`이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스텐서(`KerasTensor`)의 모양에서 `None`은 배치 사이즈, 즉 \n",
    "하나의 훈련 스텝에 사용되는 샘플의 수를 대상으로 하며, \n",
    "임의의 크기의 배치를 처리할 수 있다는 의미로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 은닉층: `features = layers.Dense(64, activation=\"relu\")(inputs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력층: `outputs = layers.Dense(10, activation=\"softmax\")(features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 빌드\n",
    "\n",
    "    ```pythoh\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KerasTensor`의 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 보았듯이 케라스텐서는 모델 훈련에 사용되는 텐서의 모양에 대한 정보를 제공하는 \n",
    "**가상의 텐서**이다.\n",
    "빌드되는 모델은 입력 케라스텐서부터 출력 케라스텐서까지 각 층에 저장된 \n",
    "텐서의 모양 정보를 이용하여 가중치 텐서와 편향 텐서를 생성하고 초기화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 다중 입력, 다중 출력 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객의 요구사항이 적힌 티켓을 처리할 때 필요한 우선순위와 담당부서를 지정하는 시스템을 구현하려 한다.\n",
    "시스템에 사용될 모델은 세 개의 입력과 두 개의 출력을 사용한다. \n",
    "\n",
    "- 입력\n",
    "    - `title`: 요구사항 타이틀. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
    "    - `text_body`: 요구사항 내용. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
    "    - `tags`: 사용자에 의한 추가 선택 사항. 멀티-핫-인코딩 사용.\n",
    "- 출력\n",
    "    - `priority`: 요구사항 처리 우선순위. 0에서 1사이의 값. 시그모이드(sigmoid) 활용.\n",
    "    - `department`: 요구사항 처리 담당 부서. 소프트맥스 활용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000    # 요구사항에 사용되는 단어 총 수\n",
    "num_tags = 100             # 태그 수\n",
    "num_departments = 4        # 부서 수\n",
    "\n",
    "# 입력층: 세 개\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "# 은닉층\n",
    "features = layers.Concatenate()([title, text_body, tags]) # shape=(None, 10000+10000+100)\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "# 출력층: 두 개\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "# 모델 빌드\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "모델 훈련을 위해 적절한 개수의 입력 텐서와 타깃 텐서를 지정해야 한다.\n",
    "여기서는 훈련 과정을 설명하기 위해 \n",
    "적절한 모양의 입력 텐서 3개와 타깃 텐서 2개를 무작위로 생성해서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 샘플 수\n",
    "num_samples = 1280\n",
    "\n",
    "# 입력 텐서 3 개 무작위 생성\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))    # 멀티-핫-인코딩\n",
    "\n",
    "# 타깃 텐서 2 개 무작위 생성\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))  # 멀티-핫-인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일 과정에서 지정된 타깃 수만큼 손실함수와 측정 기준을 지정해야 한다.\n",
    "\n",
    "- 손실함수(loss)\n",
    "    - `priority` 대상: `mean_squared_error`\n",
    "    - `department` 대상: `categorical_crossentropy`\n",
    "- 평가지표(metrics): 평가지표는 여러 개를 사용할 수 있기에 대상 별로 리스트로 지정함.\n",
    "    - `priority` 대상: `[\"mean_absolute_error\"]`\n",
    "    - `department` 대상: `[\"accuracy\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련은 `fit()` 함수에 세 개의 훈련 텐서로 이루어진 리스트와 \n",
    "두 개의 타깃 텐서로 이루어진 리스트를 지정한 후에 실행한다. \n",
    "여기서는 시험삼아 한 번의 에포크만 사용한다.\n",
    "\n",
    "- `epochs=1`\n",
    "- `batch_size=None`: 배치 크기를 지정하지 않으면 32개로 자동 지정됨.\n",
    "    그래서 스텝수가 40(= 1280/30)이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 8.4836 - priority_loss: 0.2320 - department_loss: 8.2517 - priority_mean_absolute_error: 0.3948 - department_accuracy: 0.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26e295f0a00>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가도 훈련과 동일한 방식의 인자가 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 8.7511 - priority_loss: 0.1349 - department_loss: 8.6161 - priority_mean_absolute_error: 0.2978 - department_accuracy: 0.1633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.75107192993164,\n",
       " 0.13494881987571716,\n",
       " 8.616122245788574,\n",
       " 0.29781240224838257,\n",
       " 0.16328124701976776]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측은 입력값만 리스트로 지정하고 실행하면 두 개의 어레이 출력값으로 구성된 리스트가 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16367821],\n",
       "       [0.22854233],\n",
       "       [0.32150578],\n",
       "       ...,\n",
       "       [0.2589602 ],\n",
       "       [0.24654469],\n",
       "       [0.33047378]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3337497e-04, 7.5253699e-04, 6.8721724e-01, 3.1189683e-01],\n",
       "       [3.5392201e-05, 2.0547158e-03, 8.4708840e-01, 1.5082151e-01],\n",
       "       [9.1849643e-06, 7.6845865e-04, 2.6504329e-01, 7.3417914e-01],\n",
       "       ...,\n",
       "       [2.6081441e-05, 1.3845740e-03, 4.7077110e-01, 5.2781820e-01],\n",
       "       [7.7435261e-06, 2.9441991e-03, 3.4762976e-01, 6.4941829e-01],\n",
       "       [6.6823354e-06, 1.1430271e-03, 6.9363385e-01, 3.0521649e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**사전 객체 활용**\n",
    "\n",
    "입력층과 출력층의 이름을 이용하여 사전 형식으로 입력값과 출력값을 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 6.3049 - priority_loss: 0.3365 - department_loss: 5.9684 - priority_mean_absolute_error: 0.5011 - department_accuracy: 0.2359\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.3579 - priority_loss: 0.3398 - department_loss: 3.0182 - priority_mean_absolute_error: 0.5048 - department_accuracy: 0.6172\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 층 연결 구조 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_model()`을 이용하여 층 연결 구조를 그래프로 나타낼 수 있다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier.png\")\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "**주의사항**: `pydot` 파이썬 모듈과 graphviz 라는 프로그램이 컴퓨터에 설치되어 있어야 한다.\n",
    "\n",
    "- `pydot` 모듈 설치: `pip install pydot`\n",
    "- graphviz 프로그램 설치: [https://graphviz.gitlab.io/download/](https://graphviz.gitlab.io/download/)\n",
    "- 구글 코랩에서 기본으로 지원됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 텐서와 출력 텐서의 모양을 함께 표기할 수도 있다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier_with_shapes.png\" style=\"width:900px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 모델 재활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 특성을 이용하여 새로운 모델을 빌드할 수 있다.\n",
    "먼저 모델의 `layers` 속성을 이용하여 사용된 층에 대한 정보를 확인한다. \n",
    "`layers` 속성은 사용된 층들의 객체로 이루어진 리스트를 가리킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x26e2953dc10>,\n",
       " <keras.engine.input_layer.InputLayer at 0x26e2953dcd0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x26e2953d460>,\n",
       " <keras.layers.merge.Concatenate at 0x26e2953d730>,\n",
       " <keras.layers.core.Dense at 0x26e2953d9d0>,\n",
       " <keras.layers.core.Dense at 0x26e295417f0>,\n",
       " <keras.layers.core.Dense at 0x26e29541730>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 3번 인덱스에 해당하는 층의 입력값과 출력값에 대한 정보는 아래처럼 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate_1')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "출력층을 제외한 나머지 층을 재활용해보자.\n",
    "출력층은 5번과 6번 인덱스에 위치하기에 4번 인덱스가\n",
    "가리키는 (은닉)층의 출력 정보를 따로 떼어낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 출력층에 문제해결의 어려움 정도를 \"quick\", \"medium\", \"difficult\"로\n",
    "구분하는 어려움(difficulty) 정도를 판별하는 층을 추가해보자.\n",
    "먼저, `difficulty` 층을 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "준비된 `'difficulty'` 층을 출력층으로 추가하여 \n",
    "`priority`, `department`, `difficulty`\n",
    "세 개의 출력값을 생성하는 새로운 모델을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새로 생성된 모델은 기존에 훈련된 모델의 가중치,\n",
    "즉, 은닉층에 사용된 가중치는 그대로 사용되며,\n",
    "모델 구성 그래프는 다음과 같다.\n",
    "\n",
    "```python\n",
    ">>> keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/updated_ticket_classifier.png\" style=\"width:900px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 결과는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_body (InputLayer)          [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tags (InputLayer)               [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 20100)        0           title[0][0]                      \n",
      "                                                                 text_body[0][0]                  \n",
      "                                                                 tags[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           1286464     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            65          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            260         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "difficulty (Dense)              (None, 3)            195         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,286,984\n",
      "Trainable params: 1,286,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 3: 서브클래싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 모델과 호환되는 모델 클래스를 직접 선언하여 활용하려면 `keras.Model` 클래스를 상속해야 한다.\n",
    "이런 방식을 **서브클래싱**(subclassing)이라 부르며\n",
    "`keras.Model` 클래스를 상속하면서 기본적으로 아래 두 메서드를 목적에 맞추어 재정의(overriding)하면 된다.\n",
    "\n",
    "- `__init__()` 메서드(생성자): 은닉층과 출력층의 구성요소 지정\n",
    "- `call()` 메서드: 모델 구성 후 출력값 반환\n",
    "\n",
    "앞서 함수형 API로 구성한 티켓 모델을 서브클래싱을 기법을 이용하여 구현하면 다음과 같다.\n",
    "\n",
    "**참고**: `keras.layers.Layer`를 상속하여 사용자 정의 층을 선언하는 방식과 거의 유사하다([3장 6절](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html) 참조)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):               # inputs: 사전 객체 입력값. 모양은 미정.\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])    # 은닉층\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)                 # 출력층\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department                               # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성은 해당 모델의 객체를 생성하면 된다.\n",
    "다만 `Layer`의 경우처럼 가중치는 실제 데이터와 함께 호출되지 전까지 생성되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일, 훈련, 평가, 예측인 이전과 완전히 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 8.2089 - output_1_loss: 0.3316 - output_2_loss: 7.8773 - output_1_mean_absolute_error: 0.4966 - output_2_accuracy: 0.2633\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 3.2813 - output_1_loss: 0.3398 - output_2_loss: 2.9415 - output_1_mean_absolute_error: 0.5048 - output_2_accuracy: 0.1445\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**서브클래싱 기법의 장단점**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점\n",
    "    - `call()` 함수를 이용하여 층을 임의로 구성할 수 있다.\n",
    "    - 파이썬 프로그래밍 관련 모든 기법을 적용할 수 있다.\n",
    "- 단점\n",
    "    - 사람이 모델 구성을 전적으로 책임진다.\n",
    "    - 모델 구성 정보가 `call()` 함수 외부로 노출되지 않아서\n",
    "        앞서 보았던 그래프 표현을 사용할 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 혼합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소개된 세 가지 방식을 임의로 혼합하여 활용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 서브클래싱 모델을 함수형 모델에 활용하기** (강추!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 함수형 모델을 서브클래싱 모델에 활용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.3 Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()` / `fit()` / `evaluate()` / `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2931 - accuracy: 0.9119 - val_loss: 0.1587 - val_accuracy: 0.9546\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1651 - accuracy: 0.9537 - val_loss: 0.1226 - val_accuracy: 0.9660\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1403 - accuracy: 0.9629 - val_loss: 0.1127 - val_accuracy: 0.9707\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2953 - accuracy: 0.9133 - rmse: 7.1821 - val_loss: 0.1481 - val_accuracy: 0.9570 - val_rmse: 7.3667\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1643 - accuracy: 0.9536 - rmse: 7.3568 - val_loss: 0.1133 - val_accuracy: 0.9683 - val_rmse: 7.4033\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1387 - accuracy: 0.9625 - rmse: 7.3858 - val_loss: 0.1196 - val_accuracy: 0.9703 - val_rmse: 7.4225\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1050 - accuracy: 0.9732 - rmse: 7.4350\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The `EarlyStopping` and `ModelCheckpoint` callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2935 - accuracy: 0.9126 - val_loss: 0.1553 - val_accuracy: 0.9570\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1656 - accuracy: 0.9540 - val_loss: 0.1350 - val_accuracy: 0.9640\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9625 - val_loss: 0.1201 - val_accuracy: 0.9705\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1273 - accuracy: 0.9677 - val_loss: 0.1074 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1141 - accuracy: 0.9705 - val_loss: 0.1075 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1091 - accuracy: 0.9730 - val_loss: 0.1105 - val_accuracy: 0.9729\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.1163 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0973 - accuracy: 0.9768 - val_loss: 0.1297 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9769 - val_loss: 0.1093 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0942 - accuracy: 0.9788 - val_loss: 0.1166 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26e340b5400>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1563 [..............................] - ETA: 5:12 - loss: 2.4363 - accuracy: 0.1875WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2971 - accuracy: 0.9108 - val_loss: 0.1548 - val_accuracy: 0.9568\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1641 - accuracy: 0.9536 - val_loss: 0.1278 - val_accuracy: 0.9660\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9623 - val_loss: 0.1160 - val_accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1264 - accuracy: 0.9674 - val_loss: 0.1195 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1159 - accuracy: 0.9716 - val_loss: 0.1178 - val_accuracy: 0.9746\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1091 - accuracy: 0.9736 - val_loss: 0.1114 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1079 - accuracy: 0.9747 - val_loss: 0.1042 - val_accuracy: 0.9769\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1036 - accuracy: 0.9757 - val_loss: 0.1119 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0979 - accuracy: 0.9778 - val_loss: 0.1210 - val_accuracy: 0.9774\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0919 - accuracy: 0.9801 - val_loss: 0.1175 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26bb84114f0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2922 - accuracy: 0.9141 - val_loss: 0.1612 - val_accuracy: 0.9541\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1656 - accuracy: 0.9532 - val_loss: 0.1259 - val_accuracy: 0.9666\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1404 - accuracy: 0.9619 - val_loss: 0.1233 - val_accuracy: 0.9693\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1258 - accuracy: 0.9676 - val_loss: 0.1067 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1208 - accuracy: 0.9697 - val_loss: 0.1098 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1122 - accuracy: 0.9729 - val_loss: 0.1128 - val_accuracy: 0.9752\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1087 - accuracy: 0.9739 - val_loss: 0.1054 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0993 - accuracy: 0.9765 - val_loss: 0.1050 - val_accuracy: 0.9791\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9781 - val_loss: 0.1218 - val_accuracy: 0.9762\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0939 - accuracy: 0.9785 - val_loss: 0.1244 - val_accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26e3bef7250>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 31896), started 0:02:30 ago. (Use '!kill 31896' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d6f9a53a42029dbe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d6f9a53a42029dbe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with `tf.function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging `fit()` with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Chapter summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working_with_keras",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
