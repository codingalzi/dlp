{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 7장 케라스 모델 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사말**: 프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 3장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다.\n",
    "\n",
    "**tensorflow 버전과 GPU 확인**\n",
    "- 구글 코랩 설정: '런타임 -> 런타임 유형 변경' 메뉴에서 GPU 지정 후 아래 명령어 실행 결과 확인\n",
    "\n",
    "    ```\n",
    "    !nvidia-smi\n",
    "    ```\n",
    "\n",
    "- 사용되는 tensorflow 버전 확인\n",
    "\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    tf.__version__\n",
    "    ```\n",
    "- tensorflow가 GPU를 사용하는지 여부 확인\n",
    "\n",
    "    ```python\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 케라스 모델 구성법\n",
    "- 케라스 모델 훈련 및 평가\n",
    "- 사용자 정의 모델 훈련 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.1 작업 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 이용하여 매우 단순한 모델부터 매우 복잡한 모델까지 구성 및 훈련이 가능하다. \n",
    "케라스의 모델과 층은 모두 각각 `Model` 클래스와 `Layer` 클래스를 상속하기에 \n",
    "다른 모델에서 사용된 요소들을 재활용하기에도 용이하다.\n",
    "\n",
    "여기서는 주어진 문제에 따른 케라스 모델 구성법과 훈련법의 다양한 방식을 살펴본다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.2 케라스 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스를 이용하여 모델을 세 가지 방식으로 구성할 수 있다.\n",
    "\n",
    "- `Sequential` 모델: 층으로 스택을 쌓아 만든 모델\n",
    "- 함수형 API 활용: 가장 많이 사용됨.\n",
    "- 모델 서브클래싱: 모든 것을 사용자가 지정.\n",
    "\n",
    "가장 간단한 모델부터 아주 복잡한 모델까지 모두 구성할 수 있으며\n",
    "사용자가 직접 정의한 모델과 레이어도 활용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/progressive_disclosure_of_complexity_models.png\" style=\"width:800px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 방법 1: `Sequential` 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층으로 스택을 쌓아 만든 모델이며 가장 단순하다.\n",
    "\n",
    "- 하나의 입력값과 하나의 출력값만 사용 가능\n",
    "- 층을 지정된 순서대로만 적용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`Sequential` 클래스**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "층의 추가는 `add` 메서드를 이용할 수도 있다.\n",
    "더해진 순서대로 층이 쌓인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`build()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련에 사용되는 층별 가중치는 모델이 처음 활용될 때 호출되는\n",
    "`build()` 메서드에 의해 초기화된다.\n",
    "이유는 입력값이 들어와야 가중치 텐서의 모양(shape)을 정할 수 있기 때문이다. \n",
    "아래 코드 샘플은 [3장](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html)에서 \n",
    "`SimpleDense`를 선언할 때 사용된 `build()` 메서드를 보여주며,\n",
    "훈련이 시작되면서 첫 배치 데이터셋이 입력될 때 특성 수를 확인하여\n",
    "가중치와 편향 텐서를 생성과 동시에 초기화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build(self, input_shape):\n",
    "    input_dim = input_shape[-1]   # 입력 샘플의 특성 수\n",
    "    self.W = self.add_weight(shape=(input_dim, self.units),\n",
    "                             initializer=\"random_normal\")\n",
    "    self.b = self.add_weight(shape=(self.units,),\n",
    "                             initializer=\"zeros\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 지금 당장 가중치를 확인하려 하면 오류가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> model.weights\n",
    "\n",
    "...\n",
    "ValueError: Weights for model sequential_1 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "반면에 입력값 대신 `build()` 메서드를 특성 수 정보를 이용하여 직접 호출하면\n",
    "가중치 텐서가 무작위로 초기화된 형식으로 생성된다.\n",
    "즉, **모델 빌드**가 완성된다.\n",
    "\n",
    "- `input_shape` 키워드 인자: `(None, 특성수)`\n",
    "- `None`은 임의의 크기의 배치도 다룰 수 있다는 것을 의미함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 빌드가 완성되면 `weights` 속성에 생성된 모델 훈련에 필요한 모든 가중치와 편향이 저장된다.\n",
    "위 모델에 대해서 층별로 가중치와 편향 텐서 하나씩 총 4 개의 텐서가 생성되나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2층의 가중치와 편향 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`summary()` 메서드**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성된 모델의 요악한 내용은 확인할 수 있다.\n",
    "\n",
    "- 모델과 층의 이름\n",
    "- 층별 파라미터 수\n",
    "- 파라미터 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**`name` 인자**\n",
    "\n",
    "모델 또는 층을 지정할 때 생성자 메서등의 `name` 키워드 인자를 이용하여 이름을 지정할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**모델 디버깅**\n",
    "\n",
    "모델 구성 중간에 구성 과정을 확인하려면 `Input()`함수를 이용하여\n",
    "**케라스텐서**(`KerasTensor`) 객체를\n",
    "가장 먼저 모델에 추가한다.\n",
    "그러면 층을 추가할 때마다 `summary()`를 실행할 수 있다.\n",
    "\n",
    "- `Input()` 함수: 모델 빌드에 필요한 가중치 텐서 생성에 필요한 정보를 제공하는 `KerasTensor` 객체 생성\n",
    "- **주의사항**: `shape` 키워드 인자에 사용되는 값은 각 샘플의 특성 수이며,\n",
    "    앞서 `build()` 메서드의 인자와 다른 형식으로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 방법 2: 함수형 API 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다중 입력과 다중 출력을 지원하려면 함수형 API를 활용하여 모델을 구성해야 하며,\n",
    "가장 많이 사용되는 모델 구성법이다. \n",
    "사용법은 간단하다.\n",
    "\n",
    "```python\n",
    "Model(inputs, outputs)\n",
    "```\n",
    "\n",
    "- `Model` 클래스의 객체 생성\n",
    "- `inputs` 인자: 하나의 케라스텐서 객체 또는 여러 개의 케라스텐서로 이루어진 리스트\n",
    "- `outputs` 인자: 하나의 출력층 또는 여러 개의 출력층으로 이루어진 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 `Sequential` 모델로 구성한 모델을 함수형 API를 이용하여 구성하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")          # 입력층\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)     # 은닉층\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features) # 출력층\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용된 단계들을 하나씩 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `inputs`\n",
    "\n",
    "    ```python\n",
    "    inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 값은 `KerasTensor`이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스텐서(`KerasTensor`)의 모양에서 `None`은 배치 사이즈, 즉 \n",
    "하나의 훈련 스텝에 사용되는 샘플의 수를 대상으로 하며, \n",
    "임의의 크기의 배치를 처리할 수 있다는 의미로 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 은닉층\n",
    "\n",
    "    ```python\n",
    "    features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `outputs`\n",
    "\n",
    "    ```python\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.keras_tensor.KerasTensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 빌드\n",
    "\n",
    "    ```pythoh\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`KerasTensor`의 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 보았듯이 케라스텐서는 모델 훈련에 사용되는 텐서들 관련 정보를 제공하는 **가상의 텐서**이다.\n",
    "빌드되는 모델은 입력 케라스텐서부터 출력 케라스텐서까지 각 층에 저장된 \n",
    "텐서의 모양 정보를 이용하여 가중치 텐서와 편향 텐서를 생성하고 초기화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 다중 입력, 다중 출력 모델 구성법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객이 사용하는 티켓에 따라 우선순위와 담당부서를 지정하는 모델을 구현하려 하며,\n",
    "이 모델은 세 개의 입력과 두 개의 출력을 사용한다. \n",
    "\n",
    "- 입력\n",
    "    - `title`: 티켓 종류. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
    "    - `text_body`: 티켓 내용. 문자열 인코딩. `vocabulary_size` 활용(11장에서 다룸).\n",
    "    - `tags`: 사용자에 의한 추가 선택 사항. 원(멀티?)-핫-인코딩 사용.\n",
    "- 출력\n",
    "    - `priority`: 티켓의 우선순위. 0에서 1사이의 값. 시그모이드(sigmoid) 값.\n",
    "    - `department`: 티켓 담당 부서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000    # 단어량\n",
    "num_tags = 100             # 태그 수\n",
    "num_departments = 4        # 부서 수\n",
    "\n",
    "# 입력층\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "# 은닉층\n",
    "features = layers.Concatenate()([title, text_body, tags]) # shape=(None, 10000+10000+100)\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "# 출력층\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "# 모델 빌드\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "모델 훈련을 위해 적절한 개수의 입력 텐서와 타깃 텐서를 지정해야 한다.\n",
    "여기서는 훈련 과정을 설명하기 적절한 모양의 입력 텐서 3개와 타깃 텐서 2개를 무작위로 생성해서 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags)) # 멀티-핫-인코딩(?)\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일 과정에서 타깃에 따라 각각 손실함수와 측정 기준을 지정해야 한다.\n",
    "\n",
    "- 손실함수(loss)\n",
    "    - `priority` 대상: `mean_squared_error`\n",
    "    - `department` 대상: `categorical_crossentropy`\n",
    "- 평가지표(metrics)\n",
    "    - `priority` 대상: `[\"mean_absolute_error\"]`\n",
    "    - `department` 대상: `[\"accuracy\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련은 `fit()` 함수에 세 개의 훈련 텐서로 이루어진 리스트와 \n",
    "두 개의 타깃 텐서로 이루어진 리스트를 지정한 후에 실행한다. \n",
    "여기서는 시험삼아 한 번의 에포크만 사용한다.\n",
    "\n",
    "- `epochs=1`\n",
    "- `batch_size=None`: 배치 크기를 지정하지 않으면 32개로 자동 지정됨.\n",
    "    그래서 스텝수가 40(= 1280/30)이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 11.0759 - priority_loss: 0.3273 - department_loss: 10.7486 - priority_mean_absolute_error: 0.4945 - department_accuracy: 0.2609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff578f938b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가는 훈련과 동일한 방식의 인자가 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 3ms/step - loss: 4.5811 - priority_loss: 0.3309 - department_loss: 4.2502 - priority_mean_absolute_error: 0.4991 - department_accuracy: 0.5695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.5810675621032715,\n",
       " 0.3308507800102234,\n",
       " 4.250216960906982,\n",
       " 0.4991191327571869,\n",
       " 0.569531261920929]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측은 입력값만 리스트로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 값이 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7162306 , 0.01936264, 0.03209356, 0.23231323],\n",
       "       [0.9563645 , 0.00946152, 0.00645653, 0.02771746],\n",
       "       [0.6743597 , 0.03527597, 0.07461546, 0.21574889],\n",
       "       ...,\n",
       "       [0.74637985, 0.00738816, 0.07672835, 0.16950354],\n",
       "       [0.8366549 , 0.01468116, 0.0689877 , 0.07967623],\n",
       "       [0.84758824, 0.02852361, 0.02406331, 0.09982493]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**사전 객체 활용**\n",
    "\n",
    "입력층과 출력층의 이름을 이용하여 사전 형식으로 입력값과 출력값을 지정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 5.8541 - priority_loss: 0.3309 - department_loss: 5.5232 - priority_mean_absolute_error: 0.4991 - department_accuracy: 0.3508\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.8775 - priority_loss: 0.3309 - department_loss: 2.5467 - priority_mean_absolute_error: 0.4991 - department_accuracy: 0.6398\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 층 연결 구조 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "`plot_model()`을 이용하여 층 연결 구조를 그래프로 나타낼 수 있다.\n",
    "\n",
    "**주의사항**: `pydot` 파이썬 모듈과 graphviz 라는 프로그램이 컴퓨터에 설치되어 있어야 한다.\n",
    "\n",
    "- `pydot` 모듈 설치: `pip install pydot`\n",
    "- graphviz 프로그램 설치: [https://graphviz.gitlab.io/download/](https://graphviz.gitlab.io/download/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier.png\")\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier.png\" style=\"width:400px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 텐서와 출력 텐서의 모양을 함께 표기할 수도 있다.\n",
    "\n",
    "- `show_shapes=True`: 텐서 모양 정보 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/ticket_classifier_with_shapes.png\" style=\"width:900px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### 특성 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련된 모델의 특성을 이용하여 새로운 모델을 빌드할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- `layers` 속성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7ff589f7c160>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7ff589f7c1c0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7ff589f7c190>,\n",
       " <keras.layers.merge.Concatenate at 0x7ff589f7c5e0>,\n",
       " <keras.layers.core.Dense at 0x7ff589f4af10>,\n",
       " <keras.layers.core.Dense at 0x7ff589f7cbb0>,\n",
       " <keras.layers.core.Dense at 0x7ff589f4ad30>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 3번 인덱스에 해당하는 층의 입력값과 출력값에 대한 정보는 아래처럼 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 출력층을 제외한 은닉층 재활용\n",
    "\n",
    "4번 인덱스에 위치한 은닉층까지만 재활용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력층에 새로운 출력값을 추가하고자 한다고 가정한다.\n",
    "\n",
    "- \"quick\", \"medium\", \"difficult\"을 이용하여 문제해결의 어려움 정도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 `'difficulty'`출력층을 추가하여 새로운 모델을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 그래프는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "code"
   },
   "source": [
    "```python\n",
    ">>> keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)\n",
    "```\n",
    "\n",
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/updated_ticket_classifier.png\" style=\"width:900px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 결과는 다음과 같으며, 새로 생성된 모델은 기존에 훈련된 모델의 가중치,\n",
    "즉, 은닉층에 사용된 가중치는 그대로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_body (InputLayer)          [(None, 10000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tags (InputLayer)               [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20100)        0           title[0][0]                      \n",
      "                                                                 text_body[0][0]                  \n",
      "                                                                 tags[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           1286464     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            65          dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            260         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "difficulty (Dense)              (None, 3)            195         dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,286,984\n",
      "Trainable params: 1,286,984\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 방법 3: 서브클래싱(`Model` 클래스 상속) 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 모델과 호환되는 모델 클래스를 직접 선언하여 활용하려면 `keras.Model` 클래스를 상속해야 하며,\n",
    "이는 `keras.layers.Layer`를 상속하여 사용자 정의 층을 선언하는 방식과 거의 유사하다([3장 6절](https://codingalzi.github.io/dlp/notebooks/dlp03_introduction_to_keras_and_tf.html) 참조).\n",
    "\n",
    "이런 방식을 **서브클래싱**(subclassing)이라 부르며\n",
    "`keras.Model` 클래스를 상속하면서 기본적으로 아래 두 메서드를 목적에 맞추어 재정의(overriding)하면 된다.\n",
    "\n",
    "- `__init__()` 메서드(생성자): 은닉층과 출력층 지정\n",
    "- `call()` 메서드: 입력층과 층 구성법 지정 후 출력값 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "앞서 함수형 API로 구성한 티켓 모델을 서브클래싱을 기법을 이용하여 구현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성은 해당 모델의 객체를 생성하면 된다.\n",
    "다만 `Layer`의 경우처럼 가중치는 실제 데이터와 함께 호출되지 전까지 생성되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일, 훈련, 평가, 예측인 이전과 완전히 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step - loss: 12.9407 - output_1_loss: 0.3300 - output_2_loss: 12.6107 - output_1_mean_absolute_error: 0.4991 - output_2_accuracy: 0.2266\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 7.8895 - output_1_loss: 0.3326 - output_2_loss: 7.5569 - output_1_mean_absolute_error: 0.5009 - output_2_accuracy: 0.1391\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**서브클래싱 기법의 장단점**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점\n",
    "    - `call()` 함수를 이용하여 가능한 모든 방식으로 층을 구성할 수 있다.\n",
    "    - 파이썬 프로그래밍 관련 모든 기법을 적용할 수 있다.\n",
    "- 단점\n",
    "    - 모델 구성에 대한 책임을 전적으로 사용자가 지어야 한다.\n",
    "    - 모델을 구성하는 층에 대한 정보가 `call()` 함수에 저장되어 외부로 노출되지 않아서\n",
    "        앞서 보았던 그래프 표현은 사용할 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 모델 구성법 혼합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소개된 세 가지 방식을 임의로 혼합하여 활용할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 서브클래싱 모델을 함수형 모델에 활용하기** (강추!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**예제: 함수형 모델을 서브클래싱 모델에 활용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 7.3 Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()` / `fit()` / `evaluate()` / `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2915 - accuracy: 0.9151 - val_loss: 0.1501 - val_accuracy: 0.9571\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1655 - accuracy: 0.9530 - val_loss: 0.1432 - val_accuracy: 0.9641\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1397 - accuracy: 0.9621 - val_loss: 0.1107 - val_accuracy: 0.9723\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.2944 - accuracy: 0.9120 - rmse: 7.1813 - val_loss: 0.1613 - val_accuracy: 0.9527 - val_rmse: 7.3605\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1657 - accuracy: 0.9538 - rmse: 7.3589 - val_loss: 0.1188 - val_accuracy: 0.9694 - val_rmse: 7.4019\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1406 - accuracy: 0.9616 - rmse: 7.3876 - val_loss: 0.1171 - val_accuracy: 0.9715 - val_rmse: 7.4235\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1138 - accuracy: 0.9715 - rmse: 7.4378\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The `EarlyStopping` and `ModelCheckpoint` callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2945 - accuracy: 0.9104 - val_loss: 0.1638 - val_accuracy: 0.9543\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1661 - accuracy: 0.9539 - val_loss: 0.1161 - val_accuracy: 0.9680\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1393 - accuracy: 0.9626 - val_loss: 0.1161 - val_accuracy: 0.9714\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1248 - accuracy: 0.9674 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1197 - accuracy: 0.9696 - val_loss: 0.1054 - val_accuracy: 0.9756\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1099 - accuracy: 0.9736 - val_loss: 0.1135 - val_accuracy: 0.9754\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1047 - accuracy: 0.9755 - val_loss: 0.1107 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1002 - accuracy: 0.9763 - val_loss: 0.1150 - val_accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0984 - accuracy: 0.9767 - val_loss: 0.1149 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0948 - accuracy: 0.9781 - val_loss: 0.1160 - val_accuracy: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5571ed940>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"accuracy\",\n",
    "        patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2945 - accuracy: 0.9123 - val_loss: 0.1517 - val_accuracy: 0.9571\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1653 - accuracy: 0.9545 - val_loss: 0.1248 - val_accuracy: 0.9665\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1407 - accuracy: 0.9621 - val_loss: 0.1145 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1242 - accuracy: 0.9678 - val_loss: 0.1086 - val_accuracy: 0.9745\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1163 - accuracy: 0.9705 - val_loss: 0.1125 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1115 - accuracy: 0.9720 - val_loss: 0.1109 - val_accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1062 - accuracy: 0.9750 - val_loss: 0.1168 - val_accuracy: 0.9767\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1018 - accuracy: 0.9766 - val_loss: 0.1217 - val_accuracy: 0.9767\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0999 - accuracy: 0.9780 - val_loss: 0.1154 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0959 - accuracy: 0.9782 - val_loss: 0.1211 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff579d5b520>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with `tf.function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging `fit()` with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Chapter summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
