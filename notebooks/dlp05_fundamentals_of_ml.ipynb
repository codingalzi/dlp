{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# 5장 머신러닝의 핵심 이슈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**감사말**: 프랑소와 숄레의 [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) 3장에 사용된 코드에 대한 설명을 담고 있으며 텐서플로우 2.6 버전에서 작성되었습니다. 소스코드를 공개한 저자에게 감사드립니다.\n",
    "\n",
    "**tensorflow 버전과 GPU 확인**\n",
    "- 구글 코랩 설정: '런타임 -> 런타임 유형 변경' 메뉴에서 GPU 지정 후 아래 명령어 실행 결과 확인\n",
    "\n",
    "    ```\n",
    "    !nvidia-smi\n",
    "    ```\n",
    "\n",
    "- 사용되는 tensorflow 버전 확인\n",
    "\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    tf.__version__\n",
    "    ```\n",
    "- tensorflow가 GPU를 사용하는지 여부 확인\n",
    "\n",
    "    ```python\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝의 핵심 이슈 이해: 모델 일반화와 모델 훈련 최적화 사이의 관계 조율\n",
    "- 머신러닝 모델 평가 기법\n",
    "- 모델 훈련 최적화 기법\n",
    "- 모델 일반화 성능 향상 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.1 머신러닝의 목표: 모델 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 많이 할 수록 모델은 훈련 세트에 대해 보다 좋은 성능을 보이지만 새로운 데이터에 대한 \n",
    "성능은 점점 떨어지는 과대적합 현상이 언제나 발생한다. \n",
    "머신러닝의 핵심 이슈는 모델 훈련의 **최적화**(optimization)와 \n",
    "모델 **일반화**(generalization) 사이의 관계를 적절히 조절하는 것이다.\n",
    "\n",
    "- **최적화**: 훈련 세트에 대해 가장 좋은 성능을 이끌어 내는 과정\n",
    "- **일반화**: 훈련된 모델이 처음 보는 데이터를 처리하는 능력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 과소적합과 과대적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과소적합\n",
    "    - 훈련 초반\n",
    "    - 훈련셋과 검증셋 모두에 대해 성능이 향상되는 과정\n",
    "    - 신경망이 훈련셋의 패턴을 아직 덜 파악한 상태\n",
    "\n",
    "- 과대적합\n",
    "    - 훈련셋 고유의 패턴을 학습하기 시작\n",
    "    - 새로운 데이터와 무관하거나 혼동을 주는 패턴 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/typical_overfitting.png\" style=\"width:700px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 좋은 일반화 모델 대 과대적합 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/outliers_and_overfitting.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과대적합 발생 주요 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과대적합을 발생시키는 요소는 크게 세 가지로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### 첫째: 소음(noise) 섞인 훈련셋\n",
    "\n",
    "- 적절하지 않은 데이터 또는 잘못된 레이블을 갖는 데이터 등을 **소음** 또는 **노이즈**(noise)라 부름.\n",
    "- 다음 MNNIST 이미지들처럼 불분명 한 경우:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/fucked_up_mnist.png\" style=\"width:500px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아니면 레이블이 잘못 붙어 있는 경우:\n",
    "    예를 들어, 잘못 분류도힌 1처럼 생긴 이미지를 7로 잘못 분류할 가능성이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/mislabeled_mnist.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### 둘째: 애매한 특성\n",
    "\n",
    "- 소음이 전혀 없는 데이터라 하더라도 특정 특성 영역이 여러 레이블과 연관될 수 있음.\n",
    "\n",
    "- 예제: 붓꽃 데이터의 꽃잎 길이와 너비를 활용한 \n",
    "    버시컬러(versicolor) 품종과 버지니카(virginica) 품종의 완벽한 구분 불가능."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://codingalzi.github.io/handson-ml2/slides/images/ch05/homl05-03b.png\" style=\"width:500px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 아래 오른쪽 그림이 과대적합 모델 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/overfitting_with_uncertainty.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### 셋째: 매우 드문 특성 또는 거짓 상관관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 매우 드문 특성\n",
    "    - 예제: IMDB 데이터셋에서 매우 낮은 빈도로 사용되는 단어를 훈련셋에서 포함시키는 경우.\n",
    "    - 어쩌다 한 번 사용되는 특성으로 인해 잘못된 판단이 유도될 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 거짓된 상관관계를 유발하는 훈련셋\n",
    "    - MNIST 데이터셋에 **백색 소음**(white noise)가 포함된 데이터셋과 그렇지 않은 데이터셋 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# MNIST 데이터셋 적재 및 전처리\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "# 백색 소음 추가\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "# 크기를 맞추기 위해 영 행렬 추가\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1568)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_with_noise_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1568)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_with_zeros_channels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "백색 소음이 들어간 샘플은 다음과 같이 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image_white4 = train_images_with_noise_channels[4].reshape((56, 28))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_image_white4\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영 행렬이 추가된 샘플은 다음과 같이 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image_zeros4 = train_images_with_zeros_channels[4].reshape((56, 28))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = train_image_zeros4\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성과 컴파일을 함수를 이용하여 지정한다.\n",
    "\n",
    "- 정수 레이블을 사용하기에 손실함수로 `sparse_categorical_crossentropy` 지정해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 백색 소음이 추가된 데이터셋 훈련\n",
    "    - `validation_split`: 검증셋 비율 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6226 - accuracy: 0.8122 - val_loss: 0.2744 - val_accuracy: 0.9172\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9261 - val_loss: 0.2281 - val_accuracy: 0.9306\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9500 - val_loss: 0.1419 - val_accuracy: 0.9588\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1114 - accuracy: 0.9650 - val_loss: 0.1612 - val_accuracy: 0.9509\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9749 - val_loss: 0.1446 - val_accuracy: 0.9572\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.1143 - val_accuracy: 0.9686\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.1273 - val_accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.1214 - val_accuracy: 0.9688\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1291 - val_accuracy: 0.9662\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.1472 - val_accuracy: 0.9632\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 훈련\n",
    "model = get_model()\n",
    "\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 영 행렬이 추가된 데이터셋 훈련\n",
    "    - `validation_split`: 검증셋 비율 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2875 - accuracy: 0.9161 - val_loss: 0.1470 - val_accuracy: 0.9579\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1203 - accuracy: 0.9646 - val_loss: 0.1118 - val_accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0787 - accuracy: 0.9769 - val_loss: 0.0923 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.0854 - val_accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.0836 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9905 - val_loss: 0.0783 - val_accuracy: 0.9781\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.0825 - val_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0938 - val_accuracy: 0.9758\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0866 - val_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0888 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "- 정확도 비교: 백색 소음이 포함된 훈련셋을 이용한 모델의 정확도 성능이 1% 이상 낮음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b6380f3040>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "\n",
    "epochs = range(1, 11)\n",
    "\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특성 선택**\n",
    "\n",
    "- 과대적합 문제를 위해 훈련에 유용한 특성을 선택해야함.\n",
    "- IMDB 예제: 빈도수 10,000 등 이내의 단어만 사용\n",
    "- 백색 소음 예제: 백셈 소음 부분 제거\n",
    "- 하지만 유용한 특성을 선택하는 일이 기본적으로 불가능하거나 매우 어려움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### 딥러닝 모델 일반화의 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 예제에서 확인할 수 있듯이 딥러닝 모델은 어떤 무엇도 학습할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**MNIST 모델을 임의로 섞은 레이블과 함께 훈련시키기**\n",
    "\n",
    "- 임의로 섞인 레이블을 이용한 모델 훈련\n",
    "- 훈련셋에 대한 성능은 훈련하면서 계속 향상됨.\n",
    "- 하지만 검증셋에 성능은 전혀 향상되지 않음.\n",
    "- 결론: 일반화의 어려움은 모델 보다는 사용되는 데이터셋 내부에 존재하는 정보 구조와 보다 밀접히 관련됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3169 - accuracy: 0.1020 - val_loss: 2.3048 - val_accuracy: 0.1058\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3003 - accuracy: 0.1177 - val_loss: 2.3110 - val_accuracy: 0.1041\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2914 - accuracy: 0.1280 - val_loss: 2.3148 - val_accuracy: 0.1025\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2781 - accuracy: 0.1385 - val_loss: 2.3255 - val_accuracy: 0.1026\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2593 - accuracy: 0.1521 - val_loss: 2.3357 - val_accuracy: 0.1041\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2379 - accuracy: 0.1673 - val_loss: 2.3555 - val_accuracy: 0.1030\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.2132 - accuracy: 0.1836 - val_loss: 2.3657 - val_accuracy: 0.1046\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1854 - accuracy: 0.2006 - val_loss: 2.3869 - val_accuracy: 0.1040\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1550 - accuracy: 0.2162 - val_loss: 2.3960 - val_accuracy: 0.1033\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.1223 - accuracy: 0.2344 - val_loss: 2.4316 - val_accuracy: 0.1016\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0892 - accuracy: 0.2494 - val_loss: 2.4515 - val_accuracy: 0.1006\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0541 - accuracy: 0.2666 - val_loss: 2.4707 - val_accuracy: 0.1037\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.0205 - accuracy: 0.2806 - val_loss: 2.5005 - val_accuracy: 0.1042\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9857 - accuracy: 0.2943 - val_loss: 2.5289 - val_accuracy: 0.1050\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9513 - accuracy: 0.3101 - val_loss: 2.5562 - val_accuracy: 0.1023\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.9166 - accuracy: 0.3233 - val_loss: 2.6051 - val_accuracy: 0.1058\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8835 - accuracy: 0.3378 - val_loss: 2.6293 - val_accuracy: 0.1006\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8502 - accuracy: 0.3514 - val_loss: 2.6494 - val_accuracy: 0.1015\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.8162 - accuracy: 0.3651 - val_loss: 2.6923 - val_accuracy: 0.1041\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7833 - accuracy: 0.3782 - val_loss: 2.7538 - val_accuracy: 0.1047\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7544 - accuracy: 0.3893 - val_loss: 2.7674 - val_accuracy: 0.1082\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.7200 - accuracy: 0.3998 - val_loss: 2.8033 - val_accuracy: 0.1060\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6919 - accuracy: 0.4134 - val_loss: 2.8510 - val_accuracy: 0.1007\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6622 - accuracy: 0.4231 - val_loss: 2.8922 - val_accuracy: 0.1013\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6316 - accuracy: 0.4348 - val_loss: 2.9231 - val_accuracy: 0.1028\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.6037 - accuracy: 0.4439 - val_loss: 2.9739 - val_accuracy: 0.1064\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5759 - accuracy: 0.4559 - val_loss: 3.0181 - val_accuracy: 0.1032\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5483 - accuracy: 0.4664 - val_loss: 3.0478 - val_accuracy: 0.1034\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.5222 - accuracy: 0.4748 - val_loss: 3.0814 - val_accuracy: 0.1057\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4970 - accuracy: 0.4857 - val_loss: 3.1283 - val_accuracy: 0.1043\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4716 - accuracy: 0.4950 - val_loss: 3.1800 - val_accuracy: 0.1040\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4450 - accuracy: 0.5054 - val_loss: 3.2266 - val_accuracy: 0.1059\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.4209 - accuracy: 0.5165 - val_loss: 3.2713 - val_accuracy: 0.1027\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3975 - accuracy: 0.5221 - val_loss: 3.3107 - val_accuracy: 0.1067\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3726 - accuracy: 0.5321 - val_loss: 3.3380 - val_accuracy: 0.1042\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3503 - accuracy: 0.5403 - val_loss: 3.4105 - val_accuracy: 0.1073\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3294 - accuracy: 0.5465 - val_loss: 3.4607 - val_accuracy: 0.1011\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.3033 - accuracy: 0.5588 - val_loss: 3.4977 - val_accuracy: 0.1052\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2851 - accuracy: 0.5626 - val_loss: 3.5604 - val_accuracy: 0.1043\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2624 - accuracy: 0.5710 - val_loss: 3.5959 - val_accuracy: 0.1028\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2426 - accuracy: 0.5798 - val_loss: 3.6543 - val_accuracy: 0.1044\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2225 - accuracy: 0.5861 - val_loss: 3.7200 - val_accuracy: 0.1041\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.2028 - accuracy: 0.5932 - val_loss: 3.7315 - val_accuracy: 0.1048\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1834 - accuracy: 0.6009 - val_loss: 3.8041 - val_accuracy: 0.1041\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1641 - accuracy: 0.6076 - val_loss: 3.8730 - val_accuracy: 0.1025\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1453 - accuracy: 0.6154 - val_loss: 3.8960 - val_accuracy: 0.1043\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1261 - accuracy: 0.6198 - val_loss: 3.9735 - val_accuracy: 0.1033\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.1104 - accuracy: 0.6270 - val_loss: 4.0275 - val_accuracy: 0.1057\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0935 - accuracy: 0.6323 - val_loss: 4.0470 - val_accuracy: 0.1040\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0759 - accuracy: 0.6404 - val_loss: 4.1111 - val_accuracy: 0.1058\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0576 - accuracy: 0.6453 - val_loss: 4.2017 - val_accuracy: 0.1030\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0424 - accuracy: 0.6488 - val_loss: 4.2390 - val_accuracy: 0.1051\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0270 - accuracy: 0.6569 - val_loss: 4.2745 - val_accuracy: 0.1032\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 1.0097 - accuracy: 0.6595 - val_loss: 4.3512 - val_accuracy: 0.1072\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9952 - accuracy: 0.6654 - val_loss: 4.3878 - val_accuracy: 0.1037\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9788 - accuracy: 0.6728 - val_loss: 4.4667 - val_accuracy: 0.1045\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9643 - accuracy: 0.6788 - val_loss: 4.5278 - val_accuracy: 0.1036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9500 - accuracy: 0.6833 - val_loss: 4.5737 - val_accuracy: 0.1004\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9339 - accuracy: 0.6915 - val_loss: 4.6183 - val_accuracy: 0.1046\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9227 - accuracy: 0.6915 - val_loss: 4.7183 - val_accuracy: 0.1076\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.9083 - accuracy: 0.6983 - val_loss: 4.7602 - val_accuracy: 0.1019\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8933 - accuracy: 0.7038 - val_loss: 4.8133 - val_accuracy: 0.1010\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8786 - accuracy: 0.7075 - val_loss: 4.8551 - val_accuracy: 0.1014\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8659 - accuracy: 0.7137 - val_loss: 4.9404 - val_accuracy: 0.1048\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8531 - accuracy: 0.7169 - val_loss: 5.0144 - val_accuracy: 0.1024\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8430 - accuracy: 0.7209 - val_loss: 5.0351 - val_accuracy: 0.1031\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8286 - accuracy: 0.7262 - val_loss: 5.1456 - val_accuracy: 0.1010\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8150 - accuracy: 0.7297 - val_loss: 5.1912 - val_accuracy: 0.1044\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.8031 - accuracy: 0.7339 - val_loss: 5.2359 - val_accuracy: 0.1018\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7939 - accuracy: 0.7389 - val_loss: 5.2999 - val_accuracy: 0.1025\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7807 - accuracy: 0.7436 - val_loss: 5.3717 - val_accuracy: 0.1052\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7697 - accuracy: 0.7461 - val_loss: 5.4089 - val_accuracy: 0.1043\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7568 - accuracy: 0.7503 - val_loss: 5.4898 - val_accuracy: 0.1013\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.7542 - val_loss: 5.5563 - val_accuracy: 0.1034\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7361 - accuracy: 0.7590 - val_loss: 5.6060 - val_accuracy: 0.1037\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7254 - accuracy: 0.7614 - val_loss: 5.6955 - val_accuracy: 0.1026\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7155 - accuracy: 0.7645 - val_loss: 5.7425 - val_accuracy: 0.1023\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.7054 - accuracy: 0.7695 - val_loss: 5.8211 - val_accuracy: 0.1010\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.7715 - val_loss: 5.8815 - val_accuracy: 0.1007\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6841 - accuracy: 0.7764 - val_loss: 5.9375 - val_accuracy: 0.1018\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6711 - accuracy: 0.7798 - val_loss: 6.0099 - val_accuracy: 0.1023\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.7837 - val_loss: 6.0621 - val_accuracy: 0.1032\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.7874 - val_loss: 6.1484 - val_accuracy: 0.1033\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6440 - accuracy: 0.7895 - val_loss: 6.1981 - val_accuracy: 0.1015\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6376 - accuracy: 0.7929 - val_loss: 6.2412 - val_accuracy: 0.1013\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6288 - accuracy: 0.7951 - val_loss: 6.2946 - val_accuracy: 0.1038\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6183 - accuracy: 0.7978 - val_loss: 6.3808 - val_accuracy: 0.1020\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6082 - accuracy: 0.8039 - val_loss: 6.4493 - val_accuracy: 0.1042\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6011 - accuracy: 0.8045 - val_loss: 6.6053 - val_accuracy: 0.1036\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5908 - accuracy: 0.8086 - val_loss: 6.6159 - val_accuracy: 0.1023\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5832 - accuracy: 0.8127 - val_loss: 6.6134 - val_accuracy: 0.1052\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5748 - accuracy: 0.8129 - val_loss: 6.7116 - val_accuracy: 0.1023\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5661 - accuracy: 0.8188 - val_loss: 6.8292 - val_accuracy: 0.1069\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5589 - accuracy: 0.8194 - val_loss: 6.8628 - val_accuracy: 0.1037\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5501 - accuracy: 0.8225 - val_loss: 6.9418 - val_accuracy: 0.1005\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5419 - accuracy: 0.8262 - val_loss: 7.0179 - val_accuracy: 0.1024\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5372 - accuracy: 0.8253 - val_loss: 7.0655 - val_accuracy: 0.1000\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5286 - accuracy: 0.8308 - val_loss: 7.1134 - val_accuracy: 0.1025\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5228 - accuracy: 0.8316 - val_loss: 7.1924 - val_accuracy: 0.1029\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5141 - accuracy: 0.8347 - val_loss: 7.2810 - val_accuracy: 0.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b3348d99d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### 다양체 가설과 보간법\n",
    "\n",
    "- **다양체 가설**(manifold hypothesis): 일반적인 데이터셋은 고차원상에 존재하는 \n",
    "    (저차원의) 연속이며 미분가능한 다양체를 구성한다는 가설.\n",
    "    - 모델 훈련은 바로 이 다양체를 찾아가는 과정임.\n",
    "    - 무작위로 섞은 레이블을 사용하는 위 MNIST 예제는 일반적인 데이터셋이 될 수 없음.\n",
    "- 다양체 가설에 의해 적절하게 구성된 모델이 적절한 훈련셋으로 훈련받았을 때 새로운 데이터에 대해 적절한 예측을 할 수 있는 이유를 설명할 수 있음.\n",
    "    - 모델이 찾은 연속이며 미분가능한 다양체와 학습된 데이터 정보에 보간법을 적용하여 새로운 데이터에 대해 예측 실행\n",
    "- **보간법**(interpolation): 임의의 두 점을 연결하는 연속적인 경로가 다양체 상에 존재하는 경우 훈련셋의 데이터와 \n",
    "    보간법을 이용하여 새로운 데이터에 대한 예측값 실행.\n",
    "    - 보다 큰 훈련세트를 사용할 수록 보다 좋은 모델 구현 가능\n",
    "    - 하지만 차원의 저주(curse of dimensions)에 의해 충분한 크기의 훈련셋 구하기 매우 어려움.\n",
    "    \n",
    "**참고**: 사람은 보간법 이외의 다른 능력을 사용하여 사물 예측과 구분, 주변 파악, 상황 판단 등 \n",
    "일반화에 필요한 일을 실행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/dense_sampling.png\" style=\"width:660px;\"></div>\n",
    "\n",
    "그림 출처: [Deep Learning with Python(Manning MEAP)](https://www.manning.com/books/deep-learning-with-python-second-edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 충분치 않은 훈련셋과 정규화\n",
    "\n",
    "훈련셋을 충분히 크게 만들지 못하는 경우 과대한 추측을 통해 과대적합이 발생할 가능성이 높으며,\n",
    "이를 방지하기 위해 두 가지 접근법이 있다.\n",
    "\n",
    "- 모델에 저장되는 정보를 적절하게 조정하기\n",
    "- 모델이 생성하는 다양체의 곡률 완화\n",
    "\n",
    "위 두 방법을 통해 모델이 보다 중요한 데이터의 패턴에 집중하도록 만들게 된다.\n",
    "이런식으로 과대적합을 방지하는 기법을 **정규화**(regularization)이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## 5.2 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 일반화 능력을 평가하는 다양한 방식 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Chapter summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
